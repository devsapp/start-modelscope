# 规范文档参考:
# 中文：https://github.com/Serverless-Devs/Serverless-Devs/blob/master/spec/zh/0.0.2/serverless_package_model/package_model.md#应用模型规范
# English: https://github.com/Serverless-Devs/Serverless-Devs/blob/master/spec/en/0.0.2/serverless_package_model/package_model.md#Application-model-specification
# --------------
# Package 开发发布最佳实践:
#   - [社区讨论 #62](https://github.com/Serverless-Devs/Serverless-Devs/discussions/62);
#   - [社区讨论 #407](https://github.com/Serverless-Devs/Serverless-Devs/discussions/407);
#   - [社区讨论 #439](https://github.com/Serverless-Devs/Serverless-Devs/discussions/439);

Edition: 3.0.0
Type: Project
Name: start-modelscope-v3
Provider:
  - 阿里云 
Version: dev
Description: ModelScope应用(fc3.0)
HomePage: https://github.com/devsapp/start-modelscope-v3
Tags:
  - AIGC
  - 大模型
Category: 人工智能
Organization: 阿里云函数计算（FC）
Service:
  函数计算:
    Authorities:
      - AliyunFCFullAccess
Effective: Public
Parameters:
  type: object
  additionalProperties: false
  required: # 必填项
    - region
    - imageTag
    - name
    - roleArn
    - modelId
    - accessToken
    - instanceType
    - memorySize
  properties:
    region:
      title: 地域
      type: string
      default: cn-shanghai
      description: 创建应用所在的地区
      enum:
        - cn-hangzhou
        - cn-shanghai
    imageTag:
      title: modelscope镜像tag
      type: string
      default: fc-deploy-common-v17.3.3
      description: registry.${vars.region}.aliyuncs.com/modelscope-repo/modelscope镜像的tag版本。原生流程请用fc-deploy-common-v17.3.3。
    name:
      title: 项目名
      type: string
      default: modelscope-${default-suffix}
      pattern: "^[a-zA-Z_][a-zA-Z0-9-_]{0,127}$"
      description: 项目名称，只能包含字母、数字、下划线和中划线。不能以数字、中划线开头。长度在 1-128 之间
    roleArn:
      title: 服务角色ARN
      type: string
      default: "AliyunFCDefaultRole"
      pattern: "^acs:ram::[0-9]*:role/.*$"
      description: "函数计算访问其他云服务时使用的服务角色，需要填写具体的角色ARN，格式为acs:ram::$account-id>:role/$role-name。例如：acs:ram::14310000000:role/aliyunfcdefaultrole。
      \n如果您没有特殊要求，可以使用函数计算提供的默认的服务角色，即AliyunFCDefaultRole。如果您首次使用函数计算，可以访问 https://fcnext.console.aliyun.com 进行授权。
      \n详细文档参考 https://help.aliyun.com/document_detail/181589.html?spm=5176.fcnext.help.dexternal.7bea78c8sVHoRf#section-o93-dbr-z6o"
      x-role:
        name: fcmodelscoperole
        service: fc
        authorities:
          - AliyunNASFullAccess
          - AliyunFCDefaultRolePolicy
    modelId:
      title: 模型ID
      type: string
      default: 'damo/nlp_structbert_sentiment-classification_chinese-ecommerce-base'
      description: ModelScope的模型ID, 可以从 https://modelscope.cn/models 模型页获取
    modelRevision:
      title: 模型版本
      type: string
      default: 'v1.0.0'
      description: ModelScope的模型版本，可以从 https://modelscope.cn/models 模型页获取
    modelTask:
      title: 模型任务类型
      type: string
      default: 'text-classification'
      description: ModelScope的模型任务类型，可以从 https://modelscope.cn/models 模型页获取
    accessToken:
      title: Access Token
      type: secret
      default: ''
      description: ModelScope的访问令牌（SDK令牌），从https://modelscope.cn/my/myaccesstoken获取
    instanceType:
      title: 模型运行实例类型
      type: string
      default: "fc.gpu.tesla.1"
      description: 请谨慎修改！修改时遵循：\n  1.预选为CPU时，请勿在此切换为GPU实例。反之亦然。（如：预配了CPU镜像环境，在此切换为GPU机器会由于环境无cuda，造成GPU无法使用的浪费）\n  2.修改为配置更低的硬件存在失败风险（如：显存或内存变小后，无法加载模型）。\n模型运行实例类型：e1（CPU 弹性实例）、c1（CPU 性能实例）、fc.gpu.tesla.1（GPU T4实例）、fc.gpu.ampere.1（GPU A10实例：当前A10资源较为紧张）
      enum:
        - "e1"
        - "c1"
        - "fc.gpu.tesla.1"
        - "fc.gpu.ada.1"
    gpuMemorySize:
      title: 显存大小
      type: string
      default: "16384"
      pattern: "^(0|1024|2048|3072|4096|5120|6144|7168|8192|9216|10240|11264|12288|13312|14336|15360|16384|17408|18432|19456|20480|21504|22528|23552|24576)$"
      description: 应用分配显存大小。CPU实例请配置为0。GPU实例显存规格详细信息：https://help.aliyun.com/document_detail/179379.html?spm=a2c4g.179379.0.0.2b6d15f9T9xx3o
    memorySize:
      title: 内存大小
      type: string
      default: "32768"
      pattern: "^(0|128|192|256|320|384|448|512|576|640|704|768|832|896|960|1024|1088|1152|1216|1280|1344|1408|1472|1536|1600|1664|1728|1792|1856|1920|1984|2048|2112|2176|2240|2304|2368|2432|2496|2560|2624|2688|2752|2816|2880|2944|3008|3072|3136|3200|3264|3328|3392|3456|3520|3584|3648|3712|3776|3840|3904|3968|4032|4096|4160|4224|4288|4352|4416|4480|4544|4608|4672|4736|4800|4864|4928|4992|5056|5120|5184|5248|5312|5376|5440|5504|5568|5632|5696|5760|5824|5888|5952|6016|6080|6144|6208|6272|6336|6400|6464|6528|6592|6656|6720|6784|6848|6912|6976|7040|7104|7168|7232|7296|7360|7424|7488|7552|7616|7680|7744|7808|7872|7936|8000|8064|8128|8192|8256|8320|8384|8448|8512|8576|8640|8704|8768|8832|8896|8960|9024|9088|9152|9216|9280|9344|9408|9472|9536|9600|9664|9728|9792|9856|9920|9984|10048|10112|10176|10240|10304|10368|10432|10496|10560|10624|10688|10752|10816|10880|10944|11008|11072|11136|11200|11264|11328|11392|11456|11520|11584|11648|11712|11776|11840|11904|11968|12032|12096|12160|12224|12288|12352|12416|12480|12544|12608|12672|12736|12800|12864|12928|12992|13056|13120|13184|13248|13312|13376|13440|13504|13568|13632|13696|13760|13824|13888|13952|14016|14080|14144|14208|14272|14336|14400|14464|14528|14592|14656|14720|14784|14848|14912|14976|15040|15104|15168|15232|15296|15360|15424|15488|15552|15616|15680|15744|15808|15872|15936|16000|16064|16128|16192|16256|16320|16384|16448|16512|16576|16640|16704|16768|16832|16896|16960|17024|17088|17152|17216|17280|17344|17408|17472|17536|17600|17664|17728|17792|17856|17920|17984|18048|18112|18176|18240|18304|18368|18432|18496|18560|18624|18688|18752|18816|18880|18944|19008|19072|19136|19200|19264|19328|19392|19456|19520|19584|19648|19712|19776|19840|19904|19968|20032|20096|20160|20224|20288|20352|20416|20480|20544|20608|20672|20736|20800|20864|20928|20992|21056|21120|21184|21248|21312|21376|21440|21504|21568|21632|21696|21760|21824|21888|21952|22016|22080|22144|22208|22272|22336|22400|22464|22528|22592|22656|22720|22784|22848|22912|22976|23040|23104|23168|23232|23296|23360|23424|23488|23552|23616|23680|23744|23808|23872|23936|24000|24064|24128|24192|24256|24320|24384|24448|24512|24576|24640|24704|24768|24832|24896|24960|25024|25088|25152|25216|25280|25344|25408|25472|25536|25600|25664|25728|25792|25856|25920|25984|26048|26112|26176|26240|26304|26368|26432|26496|26560|26624|26688|26752|26816|26880|26944|27008|27072|27136|27200|27264|27328|27392|27456|27520|27584|27648|27712|27776|27840|27904|27968|28032|28096|28160|28224|28288|28352|28416|28480|28544|28608|28672|28736|28800|28864|28928|28992|29056|29120|29184|29248|29312|29376|29440|29504|29568|29632|29696|29760|29824|29888|29952|30016|30080|30144|30208|30272|30336|30400|30464|30528|30592|30656|30720|30784|30848|30912|30976|31040|31104|31168|31232|31296|31360|31424|31488|31552|31616|31680|31744|31808|31872|31936|32000|32064|32128|32192|32256|32320|32384|32448|32512|32576|32640|32704|32768)$"
      description: 应用分配内存大小，GPU实例内存规格详细信息：https://help.aliyun.com/document_detail/179379.html?spm=a2c4g.179379.0.0.2b6d15f9T9xx3o#section-mfv-5fb-ehw
    modelBackend:
      title: 模型后端
      type: string
      default: "ollama"
      description: 模型运行使用的后端，当前仅支持选择ollama、pipeline。由于当前部分模型支持以pipeline的方式拉起，另一部分支持ollama。该配置为后续扩展至vllm、lmdeploy提前设定，现在配置无效。
      enum:
        - "ollama"
        - "pipeline"
    subModelFile:
      title: model_id下的子文件，如选择特定的某一个gguf文件
      type: string
      default: "gemma-2-9b-it-Q5_K_L.gguf"
      description: 子模型文件。同一个model_id下，可能存在不同精度的子模型文件（如gguf文件），指定其中一个运行
    templateFile:
      title: 模型template文件链接
      type: string
      default: "llm_template/ollama/gemma2.modelfile"
      description: 模型时所需的模型template文件的链接，使用ollama启动时为必须参数。其中gguf路径应以{gguf_file}表示，在执行时会被替换成容器内真实可访问的路径。
